{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/j91wn79j45lccf78212k1pp80000gn/T/ipykernel_6246/3103078259.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LONDON (\n"
     ]
    }
   ],
   "source": [
    "url = 'https://apnews.com/article/ai-act-europe-regulation-59466a4d8fd3597b04542ef25831322c'\n",
    "\n",
    "# use chromedriver to automate the scrolling process\n",
    "driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "html_content = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "article_content = soup.find('div', class_='RichTextStoryBody RichTextBody')\n",
    "\n",
    "if article_content:\n",
    "    eu_1_article_text = article_content.get_text(separator='\\n')\n",
    "    print(eu_1_article_text[:10])\n",
    "else:\n",
    "    print(\"Article content not found.\")\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/j91wn79j45lccf78212k1pp80000gn/T/ipykernel_6246/1922683170.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Fr\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai'\n",
    "\n",
    "# use chromedriver to automate the scrolling process\n",
    "driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "html_content = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "article_contents = soup.find_all('p', class_='ep-wysiwig_paragraph')\n",
    "\n",
    "eu_2_article_text = ''\n",
    "\n",
    "if article_contents:\n",
    "    for article_content in article_contents:\n",
    "        eu_2_article_text = eu_2_article_text + article_content.get_text(separator='\\n')\n",
    "    print(eu_2_article_text[:5])\n",
    "else:\n",
    "    print(\"Article content not found.\")\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/j91wn79j45lccf78212k1pp80000gn/T/ipykernel_6246/2036835304.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign \n"
     ]
    }
   ],
   "source": [
    "url = 'https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117'\n",
    "\n",
    "driver = webdriver.Chrome('/Users/alexyang/Documents/chromedriver-mac-arm64/chromedriver')\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "html_content = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "article_contents = soup.find_all('p', class_='selectionShareable')\n",
    "\n",
    "china_article_text = ''\n",
    "\n",
    "if article_contents:\n",
    "    for article_content in article_contents:\n",
    "        china_article_text = china_article_text + article_content.get_text(separator='\\n')\n",
    "    print(china_article_text[:5])\n",
    "else:\n",
    "    print(\"Article content not found.\")\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSTn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "uk_article_text = extract_text_from_pdf('UK_Parliament_POST.pdf')\n",
    "uk_article_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55105"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_article_text = extract_text_from_pdf('202307-Sheehan_Chinese AI gov.pdf')\n",
    "len(ch_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JULY 2023  |  REVERSE ENGINEERING CHINESE AI GOVERNANCE\\n\\nChina’s AI Regulations and \\nHow They Get Made\\n\\nMatt Sheehan\\n\\nWORKING PAPER\\x0c\\x0cChina’s AI Regulations and \\nHow They Get Made \\n\\nMatt Sheehan\\n\\n\\x0cFor your convenience, this document contains hyperlinked source notes indicated by teal-colored text.\\n\\n© 2023 Carnegie Endowment for International Peace. All rights reserved.\\n\\nCarnegie does not take institutional positions on public policy issues; the views represented herein are those \\nof the author(s) and do not necessarily reflect the views of Carnegie, its staff, or its trustees.\\n\\nNo part of this publication may be reproduced or transmitted in any form or by any means without \\npermission in writing from the Carnegie Endowment for International Peace. Please direct inquiries to:\\n\\nCarnegie Endowment for International Peace\\nPublications Department\\n1779 Massachusetts Avenue NW\\nWashington, DC 20036\\nP: + 1 202 483 7600\\nF: + 1 202 483 1840\\nCarnegieEndowment.org\\n\\nThis publication can be downloaded at no cost at CarnegieEndowment.org.\\n\\n\\x0cContents\\n\\nList of Abbreviations \\n\\nSummary \\n\\nIntroduction \\n\\nChinese AI Governance to Date \\n\\nThe Underlying Structure of China’s AI Regulations \\n\\nThe Core Motivations Driving Chinese AI Governance \\n\\nHow China Sets AI Governance Policy \\n\\nAbout the Author \\n\\nNotes \\n\\nCarnegie Endowment for International Peace \\n\\n1\\n\\n3\\n\\n7\\n\\n9\\n\\n14\\n\\n16\\n\\n18\\n\\n24\\n\\n25\\n\\n27\\n\\n\\x0c\\x0cList of Abbreviations \\n\\nCAC: Cyberspace Administration of China\\n\\nCulture: Ministry of Culture and Tourism\\n\\nEducation: Ministry of Education\\n\\nMIIT: Ministry of Industry and Information Technology\\n\\nMOST: Ministry of Science and Technology\\n\\nMPS: Ministry of Public Security\\n\\nNRTA: National Radio and Television Administration\\n\\nPublicity: Publicity Department of the CCP Central Committee \\n\\nSAMR: State Administration of Market Regulation \\n\\n11\\n\\n\\x0c\\x0cSummary\\n\\nChina is in the midst of rolling out some of the world’s earliest and most detailed regulations \\ngoverning artificial intelligence (AI). These include measures governing recommendation \\nalgorithms—the most omnipresent form of AI deployed on the internet—as well as new \\nrules for synthetically generated images and chatbots in the mold of ChatGPT. China’s \\nemerging AI governance framework will reshape how the technology is built and deployed \\nwithin China and internationally, impacting both Chinese technology exports and global  \\nAI research networks. \\n\\nBut in the West, China’s regulations are often dismissed as irrelevant or seen purely through \\nthe lens of a geopolitical competition to write the rules for AI. Instead, these regulations \\ndeserve careful study on how they will affect China’s AI trajectory and what they can teach \\npolicymakers around the world about regulating the technology. Even if countries funda-\\nmentally disagree on the specific content of a regulation, they can still learn from each  \\nother when it comes to the underlying structures and technical feasibility of different \\nregulatory approaches. \\n\\nIn this series of three papers, I will attempt to reverse engineer Chinese AI governance. I \\nbreak down the regulations into their component parts—the terminology, key concepts, \\nand specific requirements—and then trace those components to their roots, revealing how \\n\\n3\\n\\n\\x0cFigure 1. The “Policy Funnel” of China’s AI Governance\\n\\nMajor governance initiatives tend to proceed from left to right through this funnel, though often not in a linear fashion.\\n\\nReal-world\\nRoots\\n\\nXi Jinping\\nand CCP Ideology\\n\\n“World \\nof Ideas”\\n\\nParty and\\nGovernment \\nBureaucracy\\n\\nImplementation\\n\\nImpact \\nWithin China\\n\\nImpact in \\nTechnologically\\nDeveloping \\nCountries\\n\\nImpact in \\nTechnologically\\nAdvanced \\nCountries\\n\\nImpact on the \\nTrajectory of AI \\nResearch and\\nDevelopment \\nGlobally\\n\\nFINAL\\nREGULATION\\n\\nChinese academics, bureaucrats, and journalists shaped the regulations. In doing so, we have \\nbuilt a conceptual model of how China makes AI governance policy, one that can be used to \\nproject the future trajectory of Chinese AI governance (see figure 1).\\n\\nChina’s three most concrete and impactful regulations on algorithms and AI are its 2021 \\nregulation on recommendation algorithms, the 2022 rules for deep synthesis (synthetically \\ngenerated content), and the 2023 draft rules on generative AI. Information control is a \\ncentral goal of all three measures, but they also contain many other notable provisions. The \\nrules for recommendation algorithms bar excessive price discrimination and protect the \\nrights of workers subject to algorithmic scheduling. The deep synthesis regulation requires \\nconspicuous labels be placed on synthetically generated content. And the draft generative \\nAI regulation requires both the training data and model outputs to be “true and accurate,” \\na potentially insurmountable hurdle for AI chatbots to clear. All three regulations require \\ndevelopers to make a filing to China’s algorithm registry, a newly built government reposito-\\nry that gathers information on how algorithms are trained, as well as requiring them to pass \\na security self-assessment.\\n\\nStructurally, the regulations hold lessons for policymakers abroad. By rolling out a series of \\nmore targeted AI regulations, Chinese regulators are steadily building up their bureaucratic \\nknow-how and regulatory capacity. Reusable regulatory tools like the algorithm registry can \\nact as regulatory scaffolding that can ease the construction of each successive regulation, a \\nparticularly useful step as China prepares to draft a national AI law in the years ahead.\\n\\n4   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cExamining the roots of these regulations also grants insight into the key intellectual and \\nbureaucratic players shaping Chinese AI governance. The Cyberspace Administration of \\nChina (CAC) is the clear bureaucratic leader in governance to date, but that position may \\ngrow more tenuous as the focus of regulation moves beyond the CAC’s core competency of \\nonline content controls. The Ministry of Science and Technology is another key player, one \\nthat may see its profile rise due to recent government restructuring and increased focus on \\nregulating underlying AI research. Feeding into this bureaucratic rulemaking are several \\nthink tanks and scholars, notably the China Academy for Information Communications \\nTechnology and Tsinghua University’s Institute for AI International Governance.\\n\\nIn the years ahead, China will continue rolling out targeted AI regulations and laying the \\ngroundwork for a capstone national AI law. Any country, company, or institution that hopes \\nto compete against, cooperate with, or simply understand China’s AI ecosystem must exam-\\nine these moves closely. The subsequent papers in this series will dig into the details of these \\nregulations and how they came about, deepening understanding of Chinese AI governance \\nto date and giving a preview of what is likely coming around the bend.\\n\\nMatt Sheehan   |   5\\n\\n\\x0c\\x0cIntroduction\\n\\nOver the past two years, China has rolled out some of the world’s first binding national \\nregulations on artificial intelligence (AI). These regulations target recommendation algo-\\nrithms for disseminating content, synthetically generated images and video, and generative \\nAI systems like OpenAI’s ChatGPT. The rules create new requirements for how algorithms \\nare built and deployed, as well as for what information AI developers must disclose to the \\ngovernment and the public. Those measures are laying the intellectual and bureaucratic \\ngroundwork for a comprehensive national AI law that China will likely release in the years \\nahead, a potentially momentous development for global AI governance on the scale of the \\nEuropean Union’s pending AI Act. Together, these moves are turning China into a laborato-\\nry for experiments in governing perhaps the most impactful technology of this era.\\n\\nBut international discourse on Chinese AI governance often fails to take these regulations \\nseriously, to engage with either their content or the policymaking process. International \\ncommentary often falls into one of two traps: dismissing China’s regulations as irrelevant \\nor using them as a political prop. Analysts and policymakers in other countries often treat \\nthem as meaningless pieces of paper. President Xi Jinping and the Chinese Communist \\nParty (CCP) have unchecked power to disregard their own rules, the argument goes, and \\ntherefore the regulations are unimportant. Other U.S. policy actors use the specter of \\nChinese AI governance to advance their agendas. When Senate Majority Leader Chuck \\nSchumer announced his plans to begin regulating AI earlier this year, he described China’s \\nefforts as a “wake up call to the nation,” warning that the United States could not afford to \\nlet its geopolitical adversary “write the rules of the road” for AI.\\n\\n7\\n\\n\\x0cThese positions are rooted in an aspect of reality, but they also create a blind spot: the \\nregulations themselves. The specific requirements and restrictions they impose on China’s AI \\nproducts matter. They will reshape how the technology is built and deployed in the country, \\nand their effects will not stop at its borders. They will ripple out internationally as the default \\nsettings for Chinese technology exports. They will influence everything from the content \\ncontrols on language models in Indonesia to the safety features of autonomous vehicles in \\nEurope. China is the largest producer of AI research in the world, and its regulations will \\ndrive new research as companies seek out techniques to meet regulatory demands. As U.S.- \\nand Chinese-engineered AI systems increasingly play off one another in financial markets \\nand international airspace, understanding the regulatory constraints and fail-safe mecha-\\nnisms that shape their behavior will be critical to global stability. \\n\\nAnd despite China’s drastically different political system, policymakers in the United States \\nand elsewhere can learn from its regulations. China’s regulations create new bureaucratic and \\ntechnical tools: disclosure requirements, model auditing mechanisms, and technical per-\\nformance standards. These tools can be put to different uses in different countries, ranging \\nfrom authoritarian controls on speech to democratic oversight of automated decisionmaking. \\nCharting the successes, failures, and technical feasibility of China’s AI regulations can give \\npolicymakers elsewhere a preview of what is possible and what might be pointless when it \\ncomes to governing AI.\\n\\nSo what do China’s AI regulations contain? How did its massive party and state bureaucra-\\ncies formulate them? And is it possible to predict where Chinese AI governance is headed? \\nThis is the first in a series of three papers that will tackle these questions using a novel \\napproach: reverse engineering. \\n\\nThe approach begins with the finished product: the regulations on AI and algorithms that \\nChina has already adopted. The papers will break down the regulations into their compo-\\nnent parts—the terminology, concepts, and requirements embedded in them—and then \\ntrace those components backward. They will trace their progress through China’s “policy \\nfunnel” (see figure 1) by examining the political and social roots of the ideas; how they were \\nshaped by CCP ideology, influenced by international AI discourse, and debated by Chinese \\nscholars and companies; and finally formalized by bureaucratic entities. This approach will \\nclarify the specific aims and likely impacts of China’s AI regulations and help to build a \\nconceptual model for how China makes AI policy.\\n\\nThis first paper gives an overview of key Chinese AI regulations to date and an introduction \\nto the key actors and influences in the policy process. The following papers in this series will \\napply the reverse-engineering approach to three specific regulations, digging deep into their \\nideological, intellectual, and technological roots. \\n\\n8   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cThis approach builds on the work of an international community of scholars who over the \\npast decade have greatly improved analysis of Chinese technology policy by moving the \\nfocus further up the policy supply chain. Ten years ago, China’s technology policy went \\nlargely unexamined in mainstream international discourse. Today, analysts, scholars, and the \\nmedia pay much closer attention to Beijing’s policy documents, often producing translations \\nand analyses of their impact just days after their release.\\n\\nThis project aims to continue moving the focus of analysis up the supply chain by seeking \\nout the early signals of what policies are likely to come. It identifies actors from across \\nChinese academia, media, policy think tanks, corporations, and the party and state bureau-\\ncracies that signal and shape forthcoming AI governance. Ultimately, this approach aims \\nto both deeply understand China’s existing AI regulations and to help predict what new \\nmeasures may be coming around the bend.\\n\\nChinese AI Governance to Date\\n\\n“AI” and “governance” are slippery concepts. Attempting to dissect all government policies \\nthat impact this basket of technologies would further muddy China’s already-murky poli-\\ncymaking process. This paper thus focuses on a specific subset of Chinese measures: nation-\\nal-level policy documents that explicitly and primarily target AI or algorithms for regulation \\nor governance. \\n\\nThis subset excludes several laws and regulations that impact AI development, such as the \\n2021 Personal Information Protection Law. It also excludes local government regulations, \\nsuch as those covering autonomous vehicles, and national policy documents that focus on \\nstimulating the AI industry rather than regulating it. The study includes some regulations \\nthat focus on algorithms rather than AI itself. It also briefly covers government documents \\nthat lay out high-level guidance for the ethics and governance of AI. Within that scope, table \\n1 outlines ten particularly significant AI governance documents.\\n\\nMatt Sheehan   |   9\\n\\n\\x0cTable 1. Notable Chinese AI Governance Policy Documents \\n\\nDocument\\n\\nRelease Date\\n\\nBureaucratic \\nBodies (key \\nbelow)\\n\\nJuly 20, 2017\\n\\nState Council\\n\\nNotes and Key Provisions\\n\\nWhile the plan primarily focuses on encouraging AI \\ndevelopment, it also lays out a high-level timetable for \\ndeveloping AI governance regulations through 2030.\\n\\nNew Generation AI \\nDevelopment Plan\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nGovernance Principles \\nfor New Generation \\nAI: Develop \\nResponsible Artificial \\nIntelligence\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nOutline for \\nEstablishing a Rule-\\nof-Law-Based Society \\n(2020–2025)\\n\\nOriginal Chinese\\n\\nPartial English \\nTranslation\\n\\nGuiding Opinions \\non Strengthening \\nOverall Governance of \\nInternet Information \\nService Algorithms\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nJune 17, 2019\\n\\nNational New \\nGeneration AI \\nGovernance \\nExpert \\nCommittee \\n\\nIssued by an expert committee connected to the MOST, \\nthe document proffers eight principles for AI governance, \\nincluding “respect privacy,” “secure/safe and controllable,” \\nand “agile governance.”\\n\\nDecember 7, \\n2020\\n\\nCCP Central \\nCommittee\\n\\nThis party document offers a long list of social and legal \\nissues to address before 2025. It is the first CCP policy \\ndocument specifically calling for measures to address \\nrecommendation algorithms and deepfakes.\\n\\nSeptember 17, \\n2021\\n\\nCAC, Publicity, \\nEducation, \\nMOST, MIIT, \\nMPS, Culture, \\nSAMR, NRTA\\n\\nDeveloped by the CAC and co-signed by many bodies, this \\ndocument lays out general guidance for the regulation of \\nonline algorithms through 2024.\\n\\nEthical Norms for New \\nGeneration AI\\n\\nSeptember \\n25, 2021\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nNational New \\nGeneration AI \\nGovernance \\nExpert \\nCommittee\\n\\nIssued by an expert committee connected to the MOST, the \\ndocument offers high-level guidance for ethical norms that \\nshould be embedded in AI governance. These norms include \\nthat humans should maintain control over AI and bear \\nultimate responsibility for the systems.\\n\\n10   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cDocument\\n\\nRelease Date\\n\\nBureaucratic \\nBodies (key \\nbelow)\\n\\nNotes and Key Provisions\\n\\nDecember 31, \\n2021\\n\\nCAC, MIIT, MPS, \\nSAMR\\n\\nThis first major binding regulation on algorithms was \\nmotivated by government fears about algorithms controlling \\nhow news and content are disseminated online. The \\nregulation includes many provisions for content control, \\nas well as protections for workers impacted by algorithms, \\namong others. It also created the “algorithm registry” used in \\nfuture regulations.\\n\\nCCP Central \\nCommittee, \\nState Council\\n\\nBased on a 2021 draft regulation from the MOST, the \\ndocument focuses on internal ethics and governance \\nmechanisms scientists and technology developers should \\ndeploy, with AI listed as one of three areas of particular \\nconcern, along with the life sciences and medicine.\\n\\nCAC, MIIT, MPS\\n\\nThe regulation targets many AI applications used to generate \\ntext, video, and audio. It prohibits the generation of “fake \\nnews” and requires synthetically generated content to be \\nlabeled. The core motivation for the regulation was concern \\nover deepfakes. \\n\\n(Draft \\nreleased \\nAugust 27, \\n2021)\\n\\nMarch 20, \\n2022\\n\\n(Draft \\nreleased by \\nMOST on \\nJuly 28, 2021)\\n\\nNovember \\n25, 2022\\n\\n(Draft \\nreleased \\nJanuary 28, \\n2022)\\n\\nProvisions on the \\nManagement \\nof Algorithmic \\nRecommendations in \\nInternet Information \\nServices\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nOpinions on \\nStrengthening the \\nEthical Governance \\nof Science and \\nTechnology\\n\\nOriginal Chinese\\n\\n(No English \\ntranslation)\\n\\nProvisions on the \\nAdministration of \\nDeep Synthesis \\nInternet Information \\nServices\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nMeasures for the \\nManagement of \\nGenerative Artificial \\nIntelligence Services \\n(Draft for Comment)\\n\\nOriginal Chinese\\n\\nEnglish Translation\\n\\nApril 11, 2023\\n\\nCAC\\n\\nDrafted in response to the explosion in popularity of AI \\nchatbots like ChatGPT, the regulation covers almost the exact \\nsame ground as the deep synthesis regulation, but with more \\nemphasis on text generation and training data. It requires \\nproviders to ensure that both the training data and generated \\ncontent be “true and accurate.”\\n\\nNote on translation: Many stock phrases used in the titles of Chinese policy documents are translated slightly \\ndifferently by translators. This paper switches between these minor variations when referring to different documents, \\nwhile attempting to be consistent in using one translation source for each specific document, though some excep-\\ntions have been made.\\n\\nMatt Sheehan   |   11\\n\\n\\x0cThree regulations require the deepest analysis: recommendation algorithms, “deep synthe-\\nsis,” and generative AI. These interconnected documents contain the most targeted and \\nimpactful regulations to date, creating concrete requirements for how algorithms and AI are \\nbuilt and deployed in China. Below is a brief overview of each regulation. The remainder of \\nthis paper and subsequent papers will expand on the intellectual roots and key bureaucratic \\nactors behind these regulations.\\n\\nProvisions on the Management of Algorithmic Recommendations in Internet \\nInformation Services\\n\\nThe 2021 regulation on recommendation algorithms marked the start of China’s more \\ntargeted restrictions on algorithms and AI. The original motivation for the regulation was \\nCCP concern about the role of algorithms in disseminating information online. But as that \\nimperative worked its way through the policy community and bureaucracy, many other \\nadjacent applications of algorithms—from setting schedules for workers to setting prices \\nonline—were tacked on. The regulation also created a reusable bureaucratic tool that would \\nbe deployed repeatedly in future regulations.\\n\\nTracing the origin of the term “algorithmic recommendation” (算法推荐) backward \\nin Chinese state media shows that it first emerged during a 2017 CCP backlash against \\nByteDance’s news and media apps, in which user feeds were dictated by algorithms. The \\nparty viewed this as threatening its ability to set the agenda of public discourse and began \\nlooking for ways to rein in algorithms used for information dissemination. Much of the final \\nregulation is dedicated to these concerns, requiring that algorithmic recommendation service \\nproviders “uphold mainstream value orientations” and “actively transmit positive energy.” \\nThe regulation included some more concrete measures for online content control, such as \\nrequiring that platforms manually intervene in lists of hot topics on social media to ensure \\nthey reflect government priorities.\\n\\nAs policy discussions on recommendation algorithms took shape, new concerns emerged \\nthat caused authorities to add provisions addressing them. Prominent among these was \\npublic outcry over the role algorithms play in creating exploitative and dangerous work \\nconditions for delivery workers. The second paper in this series will examine how academics \\nand journalists documenting the plight of food delivery workers led to the inclusion of \\nprotections for workers in the regulation. Similarly, as Chinese authorities cracked down \\non China’s large tech platforms during 2021, they added provisions barring providers from \\nusing algorithms for anti–competitive business practices or excessive price discrimination. \\nProviders were also told not to build algorithms that “go against ethics and morals” by \\n“inducing users to become addicted or spend too much.” Individual users were also granted \\nnew rights by the regulation, including the right to turn off algorithmic recommendation \\nservices, to delete tags used to personalize recommendations, and to receive an explanation \\nwhen an algorithm has a major impact on their interests.\\n\\n12   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cFinally, the recommendation algorithm regulation created an important new tool for \\nregulators: the algorithm registry (算法备案系统, literally “algorithm filing system”). The \\nregistry is an online database of algorithms that have “public opinion properties or . . . social \\nmobilization capabilities.” Developers of these algorithms are required to submit information \\non how their algorithms are trained and deployed, including which datasets the algorithm is \\ntrained on. They are also required to complete an “algorithm security self-assessment report” \\n(算法安全自评估报告. Here, “security,” 安全，can also be translated as “safety”). Once an \\nalgorithm is successfully registered, a limited version of the filing is made public. Subsequent \\nregulations on deep synthesis and generative AI also required developers to register their \\nalgorithms. The second paper in this series will dig into the key goals and mechanisms of the \\nalgorithm registry.\\n\\nProvisions on the Administration of Deep Synthesis Internet  \\nInformation Services\\n\\nAround the same time as the CCP became concerned with recommendation algorithms \\n(2017–2019), it also identified deepfakes as a major threat to its information environment \\nand set about regulating them. During the policy incubation process, the technology compa-\\nny Tencent managed to introduce and popularize the term “deep synthesis” to describe \\nsynthetic generation of content, replacing the politically radioactive “deepfakes” with a more \\ninnocuous-sounding technical term. The new term eventually gained traction and found its \\nway into the final regulation. The third paper in this series will explore the evolution of that \\nterminology and the role of technology companies in shaping Chinese AI governance.\\n\\nThe deep synthesis regulation was scoped to include the use of algorithms to synthetically \\ngenerate or alter content online, including voice, text, image, and video content. It requires \\nthat deep synthesis content conform to information controls, that it is labeled as syntheti-\\ncally generated, and that providers take steps to mitigate misuse. The regulation includes a \\nnumber of vague censorship requirements, such as that deep synthesis content “adhere to the \\ncorrect political direction,” not “disturb economic and social order,” and not be used to gen-\\nerate fake news. When such content “might cause confusion or mislead the public,” it must \\ninclude a “conspicuous label in a reasonable position” to alert the public that it was syn-\\nthetically generated. The regulation also includes a number of provisions targeting misuse, \\nsuch as requiring that deep synthesis users register with their real names and that platforms \\nprompt users to obtain the consent of anyone whose personal information is being edited. \\nFinally, it requires that deep synthesis providers make a filing to the algorithm registry.\\n\\nThe deep synthesis regulation was years in the making, but in the end it suffered from \\nparticularly poor timing. It was finalized on November 25, 2022, just five days before the \\nrelease of ChatGPT.\\n\\nMatt Sheehan   |   13\\n\\n\\x0cMeasures for the Management of Generative Artificial Intelligence Services\\n\\nAt first glance, China’s regulatory apparatus appeared well prepared for the wave of genera-\\ntive AI applications that would follow ChatGPT. The deep synthesis regulation technically \\nincluded most forms of generative AI, such as using the technology to create or edit images, \\nvideos, voice, and text. \\n\\nBut officials at the Cyberspace Administration of China (CAC) deemed the newly minted \\ndeep synthesis regulation insufficient. The core concern behind the deep synthesis measures \\nwas deepfakes, and its requirements reflect that. Requiring labels might make sense for \\nvisual or audio deepfakes, but it will not work as well for addressing new concerns around \\ntext generated by large language models (LLMs) or the increasingly general-purpose nature \\nof the technology. In addition, the original regulation technically only covered deep synthe-\\nsis services provided through the internet, leaving a regulatory gap for generative AI services \\nthat operate offline. So Chinese regulators and policy advisers quickly set to work drafting \\na new regulation that would cover almost the exact same set of AI applications, but with an \\nupdated set of concerns in mind. \\n\\nIn April 2023, the regulators issued a draft of the new generative AI regulation for public \\ncomment. The draft reinforced many boilerplate content mandates (“embody Core Socialist \\nValues”) and required providers to submit a filing to the existing algorithm registry. It also \\nincluded several new requirements on training data and generated content that may prove \\nextremely difficult for providers to meet. The draft requires providers ensure the “truth, \\naccuracy, objectivity, and diversity” of their training data, a potentially impossible standard \\nfor LLMs that are trained on massive troves of text and images scraped from millions of \\nwebsites. That also poses a challenge for the draft’s requirement that training data not violate \\nintellectual property rights. The regulation mandates that generative AI not be discriminato-\\nry on the basis of race or sex and that generated content be “true and accurate,” an unsolved \\ntechnical problem for LLMs that are prone to “hallucinating” inaccurate or baseless claims \\nin their outputs.\\n\\nThese extremely demanding requirements for generative AI systems have kicked off a partic-\\nularly active public debate on the draft regulation. At the time of writing, Chinese scholars, \\ncompanies, and policymakers are actively discussing how to maintain effective content \\ncontrols without squashing China’s nascent generative AI industry. The third paper in this \\nseries will dive deep into how this policy debate is playing out in public workshops, academic \\nwriting, and corporate lobbying.\\n\\n14   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cThe Underlying Structure of China’s  \\nAI Regulations \\n\\nCountries and cultures may differ on the specific content of AI regulations, but they can \\nlearn from the content-agnostic structure of the regulations themselves. The above Chinese \\nregulations share three structural similarities: the choice of algorithms as a point of entry; \\nthe building of regulatory tools and bureaucratic know-how; and the vertical and iterative \\napproach that is laying the groundwork for a capstone AI law.\\n\\nAlgorithms as Point of Entry\\n\\nAI governance can utilize different parts of the AI supply chain as a point of entry. Measures \\ncan focus on regulating training data, algorithms, or computing power, or they can simply \\nimpose requirements on the final actions taken by an AI product, leaving the remedies up to \\nthe developer. China’s approach to AI governance has been uniquely focused on algorithms.\\n\\nThis choice is clearly displayed in Chinese policy discourse around regulations and the \\ndecision to make algorithms the fundamental unit for transparency and disclosure via the \\nalgorithm registry. Some companies have been forced to complete over five separate filings \\nfor the same app, each covering a different algorithm used for personalized recommendation, \\ncontent filtering, and more. The structure of the registry and the required disclosures reveal \\na belief that effective regulation entails an understanding of, and potentially an intervention \\ninto, individual algorithms.\\n\\nChina’s regulations are not exclusively focused on algorithms. The registry includes require-\\nments to disclose the sources of training data, and the draft generative AI regulation has \\nspecific requirements on the data’s diversity and “objectivity.” Many other requirements, \\nsuch as that AI-generated content “reflect Socialist Core Values,” are defined based on \\noutcomes rather than technical specifics. Where regulators focus their interventions will be \\nan important component of Chinese AI governance going forward.\\n\\nBuilding Regulatory Tools and Bureaucratic Know-How\\n\\nChina’s initial forays into governing AI have built up specific regulatory tools and broader \\nbureaucratic know-how that can be deployed in future regulations. The algorithm registry is \\na standardized disclosure tool that ministries can easily include in future regulations, refin-\\ning its requirements as needed. The information currently disclosed—such as data sources \\n\\nMatt Sheehan   |   15\\n\\n\\x0cand security self-assessments, among others—may or may not prove to be useful to regula-\\ntors. But the tool itself can act as a kind of regulatory scaffolding that eases the construction \\nof future measures governing the technology.\\n\\nLikewise, Chinese regulators are building up know-how about the technology and potential \\ninterventions. When representatives from the CAC first met with AI companies to discuss \\ntheir algorithm submissions, they reportedly “displayed little understanding of the technical \\ndetails,” forcing company representatives to “rely on a mix of metaphors and simplified \\nlanguage.” Such meetings are an awkward but likely necessary step as bureaucrats attempt \\nto grapple with a complex new technology. They help the regulators to build relationships to \\nkey players, to learn what they do not know, and to either upskill or hire to fill those gaps.\\n\\nVertical and Iterative—For Now\\n\\nStepping further back to the scope of each regulation, China has taken a regulatory ap-\\nproach that is both vertical and iterative. Vertical regulations target a specific application \\nor manifestation of a technology. This contrasts with horizontal regulations, such as the \\nEuropean Union’s AI Act, that are comprehensive umbrella laws attempting to cover all \\napplications of a given technology. No regulation is perfectly horizontal or vertical, but most \\nregulations lean in one direction or the other. \\n\\nChina’s first batch of algorithm and AI regulations are relatively vertical. Each covers a \\nbasket of related applications that Chinese regulators are concerned about and imposes \\nrequirements specific to these concerns. The baskets of applications are relatively large; for \\nexample, the recommendation algorithm regulation covers things from social media feeds to \\nalgorithms that set expected wait times for food delivery. \\n\\nIn addition to being vertical, the regulations are iterative. If the government deems a regula-\\ntion it has issued to be flawed or insufficient, it will simply release a new one that plugs holes \\nor expands the scope, as it did with the generative AI draft regulation expanding on the deep \\nsynthesis measures. This iterative process can lead to confusion for companies doing com-\\npliance, but Chinese regulators view that as an acceptable cost in regulating a fast-changing \\ntechnology environment.\\n\\nThe vertical and iterative approach of the past few years now appears to be building toward \\nsomething more ambitious. In June 2023, China’s State Council—the rough equivalent of \\nthe U.S. Cabinet—announced that this year it would begin preparations on a draft Artificial \\nIntelligence Law (人工智能法) to be submitted to the National People’s Congress, China’s \\nlegislature. Details remain sparse, but Chinese scholars anticipate that the law will build on \\nthe existing regulations to create a more comprehensive, horizontal piece of legislation that \\nacts as a capstone on Chinese AI policy.\\n\\n16   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cThe Core Motivations Driving Chinese  \\nAI Governance\\n\\nAt a high level, China’s existing AI regulations are motivated by three main goals and one \\nauxiliary goal. \\n\\nThe first, overriding goal is to shape the technology so that it serves the CCP’s agenda, \\nparticularly for information control and, flowing from this, political and social stability. The \\nprimacy of control over information shows up clearly in the choice to first tackle AI and \\nalgorithms’ influence on online content. From the CCP’s perspective, for a technology to be \\nproductive it first must be tamed. As Chinese AI governance matures, this focus will likely \\nevolve to include more industrial or security-related applications of the technology.\\n\\nThe second major goal behind Chinese AI governance is both obvious and frequently over-\\nlooked: to address the myriad social, ethical, and economic impacts AI is having on people \\nin China. The CCP prizes political control over nearly all else, but the Chinese academics, \\npolicy analysts, journalists, and technocrats who are shaping the regulations are much like \\ntheir counterparts abroad—they are genuinely grappling with the diverse ways in which AI \\nwill change the lives of Chinese people. One example is in the regulatory provisions protect-\\ning workers whose schedules and salaries are set by algorithms. Chinese policy actors operate \\nin a far more politically constrained environment than their peers in liberal democracies, \\nwith certain topics taboo and many policy prescriptions off the table. But even within those \\nconstraints, there is still substantial room to explore the challenges of AI and to experiment \\nwith regulatory interventions to mitigate them. \\n\\nThe third goal is to create a policy environment conducive to China becoming the global \\nleader in AI development and applications. The 2017 New Generation AI Development \\nPlan laid out the goal of global AI leadership by 2030, which led to an explosion in industry \\nactivity and policy support for AI development. The CCP sees technology as a critical tool \\nfor boosting China’s economy and national power. While the policies examined here focus \\non regulating rather than stimulating the AI industry, the long-standing goal of AI leader-\\nship remains an important consideration shaping the regulatory debate. This is particularly \\nprominent in the ongoing debates over how to balance the competing needs for information \\ncontrol and technological leadership in the draft generative AI regulation.\\n\\nFinally, there remains one auxiliary goal: making China a leader in the governance and reg-\\nulation of AI. U.S. and Chinese leaders frequently point out that China has laid out some of \\nthe world’s first binding regulations on AI, with the latter using it as a point of pride and the \\nformer as an impetus to action. But the rhetorical emphasis on global leadership often leads \\nto a mistaken impression that this is a major driver of Chinese actions. An examination of \\nthe regulations and conversations with Chinese policy actors indicates otherwise. For China, \\n\\nMatt Sheehan   |   17\\n\\n\\x0cbeing a global leader or model for AI governance is a “nice-to-have”—a small bonus for its \\nbusinesses and national soft power, but not a significant driver of these AI regulations.\\n\\nChina’s choice of first targets for regulation—recommendation algorithms and deep \\nsynthesis—indicates that global leadership is not a core motivation for its AI governance. \\nRecommendation algorithms are an omnipresent application of AI, but they are not a major \\nstrand of the global discourse on AI governance. If a country wanted to stake its claim to \\nleading the world in AI governance, recommendation algorithms would not be the first \\ntarget. In fact, China’s regulation on recommendation algorithms does not even contain the \\nterm “artificial intelligence” in its text, despite covering many AI applications. Similarly, the \\nterm “deep synthesis” is not found in the AI governance discourse outside of China. \\n\\nChinese policy actors have even described the first-mover nature of their regulations as an \\nadded difficulty. When China began work on these regulations, the debates on the EU’s \\nAI Act were well underway in Europe, and Chinese policy analysts hoped that they could \\nfollow those debates and learn from the act. But slow progress on the AI Act meant that they \\nhad to forge ahead without the benefit of international guideposts or comparisons. For the \\nUnited States, one benefit of its comparatively slow progress on AI governance is the op-\\nportunity to learn from regulatory experiments abroad—if policymakers are willing to take \\nforeign regulations seriously.\\n\\nFigure 2. The Four Layers of Chinese AI Governance Policymaking\\n\\nReal-world\\nRoots\\n\\nChina’s macro \\neconomic, political, \\nsocial, and techno-\\nlogical environment\\n\\nXi Jinping\\nPriorities and\\nCCP Ideology\\n\\n“World \\nof Ideas”\\n\\nPolitical and intellectual \\nﬁlters through which \\npolicymakers view \\nproblems\\n\\nPolicy and\\nacademic debates, \\nbusiness lobbying\\n\\nParty and\\nGovernment \\nBureaucracy\\n\\nKey ministries and CCP \\nbodies crafting AI \\nregulations\\n\\n18   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cHow China Sets AI Governance Policy\\n\\nThis paper presents a four-layered policy funnel through which China formulates and pro-\\nmulgates AI governance regulations (see figure 2). Those four layers are real-world roots; Xi \\nJinping and CCP ideology; the “world of ideas”; and the party and state bureaucracies. These \\nlayers are porous, and regulations do not proceed through them in a purely linear fashion. \\nInstead, they often pinball forward and backward through these layers, getting shaped \\nand reshaped by academics, bureaucrats, public opinion, and CCP ideology. The order and \\nrelative importance of the layers also varies depending on the nature of the issue confronted. \\nSo far, most of the activity in the crafting of AI regulations has occurred in the third and \\nfourth layers.\\n\\nReal-World Roots\\n\\nThis layer is composed of the economic, political, social, and technological conditions that \\ncreate the need for new policy and also limit the options for regulators. Like public policy \\nanywhere in the world, Chinese AI regulations often get their initial impetus from an \\nexogenous shift in the real world. This can be a major evolution in technological capabilities, \\na new business model emerging, or a shift in underlying social or political conditions in \\nthe country. Such changes provide a spark, a problem that needs to be addressed through a \\nchange in public policy. The other components of this layer—economic, political and social \\nconditions—then help set the scope of what is possible with a regulation and what costs  \\nare acceptable. \\n\\nIn the recent draft generative AI regulation, the spark clearly derived from the leap in perfor-\\nmance of large language models, demonstrated by ChatGPT, and the wave of public interest \\nthat followed. The policy response to that is now being shaped by factors such as China’s \\nglobal standing in AI and its medium-term economic growth prospects.  \\n\\nXi Jinping and CCP Ideology\\n\\nWhile the real-world roots provide a spark and some macro-level constraints, the second \\nlayer defines the problem and imposes its own constraints on the policy response. In \\nChina, Xi Jinping’s worldview and the CCP’s evolving ideological frameworks are guides \\nfor interpreting events in the world and for deciding what constitutes a problem in need of \\naddressing and how that problem should be understood and responded to.\\n\\nThe term “CCP ideology” is used here somewhat loosely, including not just ideology that is \\nformally enshrined in the party’s documents and ideological journals but also the broader \\nway in which the party sees the world. The same goes for Xi and his formal contributions \\n\\nMatt Sheehan   |   19\\n\\n\\x0cto CCP ideology. He has rarely addressed specific AI regulatory issues, but the high-level \\npriorities he sets serve as guidance for all policy actors as they address concrete issues.\\n\\nThis raises one of the most common misconceptions about how China sets AI policy. Xi’s \\ndecade-long and hugely successful campaign to centralize political power in his hands has \\nled many outside observers to believe that he makes all meaningful decisions on policy \\nand regulation. Xi certainly acts as a micromanager on certain issues. Examples include \\ngiving feedback on ministry plans to crack down on the private tutoring sector, signing off \\non high-level corruption detentions, and making the decision to cancel Ant Group’s initial \\npublic offering after Alibaba founder Jack Ma criticized the government. Most famously, Xi \\ntied himself directly to China’s strict “dynamic Zero COVID” strategy that saw major cities \\nlocked down for months on end. When Xi takes a major interest in an issue, he can dictate \\npolicy, or at least reject versions of it that he does not like.\\n\\nBut it does not appear that Xi has applied this micromanagement to AI governance so far. \\nState media have not described him as directing the regulations, as they often do in other \\nareas. And the regulations do not bear the normal hallmarks of an intervention by Xi: a \\nhard-line, uncompromising approach to complex policy trade-offs. Instead, provisions in the \\nregulations can often be traced back to the work of Chinese think tanks or academics, as \\nfuture papers will show. \\n\\nThis is not to say Xi’s words do not carry tremendous power in AI policy. When he stated \\nin a 2018 speech that China must “ensure AI is safe [or secure], reliable, and controllable,” \\nthat set up high-level goals for policymakers to strive for, while leaving the details to them. \\nIn AI governance, Xi is best thought of as setting the direction of travel for policy actors and \\nas providing the ultimate backstop for decisions. Policymaking will broadly focus on the \\nissues he prioritizes and take an approach resonant with his way of seeing the world. And no \\ndecision will be made that directly contradicts his expressed wishes. But when it comes to \\ncrafting Chinese AI regulations, most of the activity has so far occurred in the next  \\ntwo layers.\\n\\nWorld of Ideas\\n\\nOnce a real-world change has thrown up an issue that needs addressing, and after the \\nissue has been filtered through the prism of Xi Jinping and CCP ideology, it enters perhaps \\nthe most dynamic layer. This is the world of ideas, where the problem and its solution are \\ndebated by actors ranging from think tank scholars to AI scientists, and from investigative \\njournalists to corporate lobbyists. This is where many policy ideas are generated or shot \\ndown. It is where technology companies try to steer the policy dialogue in their preferred \\ndirection and where journalists can bring social issues into mainstream public discourse. \\nWhile these public debates do not settle policy, they provide the intellectual grist for the \\nbureaucratic mill.\\n\\n20   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cThe Policy Funnel of Chinese AI Governance\\nClick on a section of the diagram above to learn more about the key actors and inﬂuences on \\nmajor AI governance initiatives in China.\\n\\nFigure 3. Exploring the “Policy Funnel” of Chinese AI Governance\\n\\nReal-world Roots\\n\\nP\\nu\\nb\\n\\nl\\ni\\nc\\nO\\np\\nn\\no\\nn\\n\\ni\\n\\ni\\n\\nA\\n\\nI\\nC\\na\\np\\na\\nb\\n\\ni\\nl\\ni\\nt\\ni\\ne\\ns\\na\\nn\\nd\\nB\\nu\\ns\\ni\\nn\\ne\\ns\\ns\\nM\\no\\nd\\ne\\nl\\ns\\n\\nE\\nc\\no\\nn\\no\\nm\\ny\\na\\nn\\nd\\nL\\na\\nb\\no\\nr\\n\\nD\\no\\nm\\ne\\ns\\nt\\ni\\nc\\nP\\no\\n\\nl\\ni\\nt\\ni\\nc\\na\\nl\\n\\nE\\nn\\nv\\ni\\nr\\no\\nn\\nm\\ne\\nn\\nt\\n\\nI\\nn\\nt\\ne\\nr\\nn\\na\\nt\\ni\\no\\nn\\na\\nl\\n\\nE\\nn\\nv\\ni\\nr\\no\\nn\\nm\\ne\\nn\\nt\\n\\nC\\nC\\nP\\nI\\nd\\ne\\no\\no\\ng\\ny\\n\\nl\\n\\nX\\n\\ni\\nJ\\ni\\nn\\np\\nn\\ng\\n\\ni\\n\\n“World \\nof Ideas”\\n\\nM\\ne\\nd\\ni\\na\\n\\nC\\no\\nm\\np\\na\\nn\\ni\\ne\\ns\\n\\nA\\nc\\na\\nd\\ne\\nm\\ni\\nc\\ns\\n,\\n\\ni\\n\\nT\\nh\\nn\\nk\\nT\\na\\nn\\nk\\ns\\n,\\n\\nA\\nd\\nv\\ni\\ns\\no\\nr\\ns\\n\\nI\\nn\\nt\\ne\\nr\\nn\\na\\nt\\ni\\no\\nn\\na\\nl\\n\\nA\\n\\nI\\n\\nD\\ne\\nb\\na\\nt\\ne\\ns\\n\\nS\\nt\\na\\nt\\ne\\nC\\no\\nu\\nn\\nc\\ni\\nl\\n\\nC\\ne\\nn\\nt\\nr\\na\\nl\\n\\nC\\no\\nm\\nm\\n\\ni\\nt\\nt\\ne\\ne\\n\\nC\\nA\\nC\\n\\nM\\nO\\nS\\nT\\n\\nD\\nr\\na\\nf\\nt\\nR\\ne\\ng\\nu\\nl\\na\\nt\\ni\\no\\nn\\n\\nO\\nt\\nh\\ne\\nr\\nO\\nr\\ng\\ns\\n\\nEconomy and Labor\\nA growing economy and healthy labor markets are core to Chinese social stability, making \\nthem major, though indirect, factors in AI regulation. Economic and labor conditions that gave \\nrise to the “Common Prosperity” agenda and anti-monopoly actions have likely contributed to \\nprovisions on recommendation algorithms covering antitrust and worker rights.\\n\\nTo use this interactive, please visit CarnegieEndowment.org\\n\\nAs described above, the debates occur within a constrained political and intellectual envi-\\nronment (see figure 3). Few of these policy actors will swim against the ideological stream, \\nand policy solutions that contravene Xi’s expressed wishes will not be entertained. How \\nmuch latitude these actors have depends on the political salience of the issue at stake. For \\nhighly sensitive political issues, such as the status of Taiwan, the bounds of public discussion \\nare extremely narrow. And what counts as political and sensitive has continuously expanded \\nunder Xi. \\n\\nMatt Sheehan   |   21\\n\\nXi Jinping andCCP IdeologyParty andGovernmentBureaucracy \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cNevertheless, in the area of AI regulation there is still a relatively large space for policy \\ndebates. This is perhaps due to the relatively technical nature of policies and to the freshness \\nof the problems. How to effectively regulate AI remains a wide-open question globally, and \\nthe political interests at play in China are not yet entrenched. Ministries and state-owned \\nenterprises have not spent decades fighting to gain leverage or to hang onto preferential pol-\\nicies they have carved out. This mix of factors has made public debates over AI governance \\nunusually lively and open.\\n\\nWithin that debate, several Chinese organizations and individuals stand out. Among think \\ntanks, the China Academy for Information and Communication Technology (CAICT, 中\\n国信息通信研究院) has emerged as particularly influential. Under the supervision of the \\nMinistry of Industry and Information Technology (MIIT), CAICT is home to technical \\nexperts and policy analysts who have worked closely with the CAC on AI governance proj-\\nects. Tsinghua University’s Institute for AI International Governance (清华大学人工智能\\n国际治理研究院) has also produced sophisticated reports drawing lessons from algorithm \\ngovernance abroad and making recommendations for China. Among the many Chinese \\nscholars contributing to the country’s AI governance debates, some particularly notable \\nindividuals are Zhang Linghan (张凌寒) of the China University of Political Science and \\nLaw, Sun Ping (孙萍) of the Chinese Academy of Social Sciences, and Liang Zheng (梁正) \\nand Xue Lan (薛澜) from Tsinghua University. Subsequent papers in this series will explore \\nthe contributions these and other scholars have made to Chinese AI governance.\\n\\nParty and State Bureaucracies\\n\\nIdeas and proposals are molded into regulations in the final layer of the policy funnel, \\nconsisting of the party and state bureaucracies. When it comes to setting AI regulation, \\norganizations across the party and state bureaucracies are deeply interwoven. But that prox-\\nimity should not be mistaken for harmonious relations. China’s ministries and agencies are \\na notoriously “fractious and highly competitive group,” always angling for their policies to \\nbe adopted at higher levels. Examining the regulations issued so far illuminates some initial \\nconclusions about which members of this “fractious” group are prevailing in the competition \\nfor influence. \\n\\nThe CAC has emerged as the clear leader in the first wave of AI regulations. Tracing the \\nroots of these regulations backward shows the CAC playing a leading role in setting the \\nagenda and getting its pet issues in front of the highest decisionmaking bodies, such as the \\nCCP Central Committee. When the Central Committee then approves those issues for reg-\\nulation, the CAC has authored the drafts of the regulations. In writing the draft regulations, \\nthe CAC often utilizes experts affiliated with other bodies, such as scholars from think tanks \\naffiliated with the MIIT or the Ministry of Science and Technology (MOST). It then brings \\n\\n22   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cother ministries and agencies on as co-signatories when the draft becomes final, creating \\nbureaucratic buy-in and enhancing enforcement capabilities. In this way, the CAC has acted \\nas a hub for AI regulations. \\n\\nWhether the CAC will continue to play this role remains an open question. The CAC’s \\nraison d’être is controlling online content, which made it a logical leader for the first batch \\nof AI and algorithm regulations. But as AI governance shifts to other arenas such as auton-\\nomous vehicles, fintech, or frontier AI research, it is unclear if it will be able to maintain its \\ncurrent position in leading and coordinating the other ministries.\\n\\nThe MOST played a large role in early policies like the 2017 AI plan and followed that up \\nby establishing committees and issuing high-level principles for AI ethics and governance. It \\nalso wrote the draft version of a broader technology ethics and governance measure that was \\nlater issued by the CCP Central Committee. But the MOST has taken a back seat on the \\nmore targeted regulations, not co-signing the recommendation algorithm or deep synthesis \\nregulations. The ministry focuses primarily on issues related to research and development, \\nmaking it less suited to regulating online content or certain commercial applications of AI. \\nBut the MOST’s profile may rise again as regulatory attention turns toward the underlying \\ntechnology, as in the draft generative AI regulation, which imposes requirements on  \\nmodel training.\\n\\nBeyond the CAC and the MOST, three of the more significant bureaucratic bodies are \\nthe MIIT, the Ministry of Public Security (MPS), and the State Administration of Market \\nReform (SAMR). The MIIT and the MPS have co-signed both the recommendation algo-\\nrithm and deep synthesis regulations, while SAMR signed only the former.  Each of these \\norganizations will likely continue playing a significant role in regulations that touch on their \\nrespective areas. The MIIT, in particular, will likely take on a greater role as AI regulation \\nmoves from online content to industrial and commercial applications of the technology.\\n\\nAbove all these ministries sits China’s State Council and the National People’s Congress. \\nThough these organizations have not been involved in recent AI regulations, they will be \\nthe key gatekeepers for China’s promised national AI law. While that legislative role confers \\nthem significant decisionmaking power, much of the policy formulation and bureaucratic \\nwrangling underpinning the law will likely occur within and between the subordinate \\nministries and administrations, particularly those listed above.\\n\\nFinally, lurking in the background are two new bodies created by party-state institutional \\nreforms announced in March 2023: the CCP Central Science and Technology Commission \\n(CSTC) and the National Data Administration (NDA). Neither has been formally stood up, \\nand information on them remains scare. The CSTC will serve as the CCP’s top science and \\n\\nMatt Sheehan   |   23\\n\\n\\x0ctechnology policymaking body. It will likely have a significant voice in AI regulatory policy, \\nbut it appears that the majority of its portfolio will focus on technology development—in-\\ncluding major national research projects and national laboratories—rather than regulation. \\nThe CSTC will reportedly be housed in the MOST, likely giving a boost to the latter in \\nAI governance. The NDA will focus on data infrastructure and the utilization of data to \\nsupport economic and social policies. These two bodies will merit close examination as  \\nthey take shape. \\n\\nConclusion\\n\\nChinese AI governance is approaching a turning point. After spending several years explor-\\ning, debating, and enacting regulations that address specific AI applications, China’s policy-\\nmaking community is now gearing up to draft a comprehensive national AI law.\\n\\nThat process echoes the evolution of Chinese regulations governing the internet. For much \\nof the 2000s and early 2010s, Chinese internet governance took the form of narrow regula-\\ntions issued by government ministries. As those specific internet regulations added up, the \\nChinese state began formulating a wider capstone piece of legislation that would draw and \\nbuild upon those regulations: China’s monumental Cybersecurity Law of 2017. \\n\\nChina now appears to be following that same blueprint for AI, though on an accelerated \\ntime line. There are no firm deadlines for the national AI law, but a draft version could be \\nreleased in late 2023 or 2024, followed by six to eighteen months dedicated to revising the \\nlaw. During that time, many of the organizations, individuals, and intellectual influences \\ndescribed in this paper will be shaping one of the world’s most important pieces of legisla-\\ntion for AI governance. The subsequent papers in this series will dig deeper into key players \\nin this process, illustrating how China formulates AI regulations and previewing what likely \\nlies ahead.\\n\\n24   |   China’s AI Regulations and How They Get Made\\n\\n\\x0cAbout the Author\\n\\nMatt Sheehan is a fellow at the Carnegie Endowment for International Peace, where his \\nresearch focuses on global technology issues, with a specialization in China’s artificial \\nintelligence ecosystem.\\n\\n25\\n\\n\\x0c\\x0cCarnegie Endowment for \\nInternational Peace\\n\\nThe Carnegie Endowment for International Peace is a unique global network of policy  \\nresearch centers around the world. Our mission, dating back more than a century, is to \\nadvance peace through analysis and development of fresh policy ideas and direct engagement \\nand collaboration with decisionmakers in government, business, and civil society. Working \\ntogether, our centers bring the inestimable benefit of multiple national viewpoints to  \\nbilateral, regional, and global issues.  \\n\\nAsia Program\\n\\nThe Carnegie Asia Program studies disruptive security, governance, and technological risks \\nthat threaten peace and growth in the Asia Pacific region.\\n\\n27\\n\\n\\x0cCarnegieEndowment.org\\x0c'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6761\n",
      "5317\n",
      "45779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74926"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(eu_1_article_text))\n",
    "print(len(eu_2_article_text))\n",
    "print(len(china_article_text))\n",
    "len(uk_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexyang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alexyang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLONDON (AP) — European Union negotiators clinched a deal Friday on the world’s first comprehensive artificial intelligence rules, paving the way for legal oversight of AI technology that has promised to transform everyday life and spurred \\nwarnings of existential dangers to humanity\\n.\\nNegotiators from the European Parliament and the bloc’s 27 member countries overcame big differences on controversial points including generative AI and police use of face recognition surveillance to sign a tentative political agreement for the \\nArtificial Intelligence Act\\n.\\n“Deal!” tweeted European Commissioner Thierry Breton just before midnight. “The EU becomes the very first continent to set clear rules for the use of AI.”\\n\\n\\n\\n\\nThe result came after marathon closed-door talks this week, with the initial session lasting 22 hours before a second round kicked off Friday morning.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    READ MORE\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOne Tech Tip: Ready to go beyond Google? Here’s how to use new generative AI search sites\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSora is ChatGPT maker OpenAI’s new text-to-video generator. Here’s what we know about the new tool\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpenAI reveals Sora, a tool to make instant videos from written prompts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOfficials were \\nunder the gun to secure a political victory\\n for the flagship legislation. Civil society groups, however, gave it a cool reception as they wait for technical details that will need to be ironed out in the coming weeks. They said the deal didn’t go far enough in protecting people from harm caused by AI systems. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n“Today’s political deal marks the beginning of important and necessary technical work on crucial details of the AI Act, which are still missing,” said Daniel Friedlaender, head of the European office of the Computer and Communications Industry Association, a tech industry lobby group. \\nThe EU took an \\nearly lead in the global race\\n to draw up AI guardrails when it unveiled the first draft of its rulebook in 2021. The recent boom in generative AI, however, sent European officials scrambling to update a proposal poised to serve as a blueprint for the world.\\nThe European Parliament will still need to vote on the act early next year, but with the deal done that’s a formality, Brando Benifei, an Italian lawmaker co-leading the body’s negotiating efforts, told The Associated Press late Friday.\\n\\n\\n\\n\\n“It’s very very good,” he said by text message after being asked if it included everything he wanted. “Obviously we had to accept some compromises but overall very good.” The eventual law wouldn’t fully take effect until 2025 at the earliest, and threatens stiff financial penalties for violations of up to 35 million euros ($38 million) or 7% of a company’s global turnover. \\nGenerative AI systems like OpenAI’s ChatGPT have exploded into the world’s consciousness, dazzling users with the ability to produce human-like text, photos and songs but raising fears about the risks the rapidly developing technology poses to jobs, privacy and \\ncopyright protection\\n and even \\nhuman life itself\\n. \\nNow, \\nthe U.S.\\n, \\nU.K.\\n, China and global coalitions like the Group of 7 major democracies have jumped in with their own proposals to regulate AI, though they’re still catching up to Europe.\\nStrong and comprehensive rules from the EU “can set a powerful example for many governments considering regulation,” said Anu Bradford, a Columbia Law School professor who’s an expert on EU law and digital regulation. Other countries “may not copy every provision but will likely emulate many aspects of it.”\\nAI companies subject to the EU’s rules will also likely extend some of those obligations outside the continent, she said. “After all, it is not efficient to re-train separate models for different markets,” she said. \\n\\n\\n\\n\\nThe AI Act was originally designed to mitigate the dangers from specific AI functions based on their level of risk, from low to unacceptable. But lawmakers pushed to expand it to foundation models, the advanced systems that underpin general purpose AI services like ChatGPT and \\nGoogle’s Bard chatbot\\n. \\nFoundation models looked set to be one of the biggest sticking points for Europe. However, negotiators managed to reach a tentative compromise early in the talks, despite opposition led by France, which called instead for self-regulation to help homegrown European generative AI companies competing with big U.S rivals, including OpenAI’s backer Microsoft. \\nAlso known as large language models, these systems are trained on vast troves of written works and images scraped off the internet. They give generative AI systems the \\nability to create something new\\n, unlike traditional AI, which processes data and completes tasks using predetermined rules. \\nThe companies building foundation models will have to draw up technical documentation, comply with EU copyright law and detail the content used for training. The most advanced foundation models that pose “systemic risks” will face extra scrutiny, including assessing and mitigating those risks, reporting serious incidents, putting cybersecurity measures in place and reporting their energy efficiency. \\nResearchers have warned that powerful foundation models, built by a handful of big tech companies, could be used to supercharge \\nonline disinformation and manipulation\\n, cyberattacks or creation of bioweapons. \\n\\n\\n\\n\\nRights groups also caution that the lack of transparency about data used to train the models poses risks to daily life because they act as basic structures for software developers building AI-powered services. \\nWhat became the thorniest topic was AI-powered face recognition surveillance systems, and negotiators found a compromise after intensive bargaining.\\nEuropean lawmakers wanted a full ban on public use of face scanning and other “remote biometric identification” systems because of privacy concerns. But governments of member countries succeeded in negotiating exemptions so law enforcement could use them to tackle serious crimes like child sexual exploitation or terrorist attacks. \\nRights groups said they were concerned about the exemptions and other big loopholes in the AI Act, including lack of protection for AI systems used in migration and border control, and the option for developers to opt-out of having their systems classified as high risk. \\n“Whatever the victories may have been in these final negotiations, the fact remains that huge flaws will remain in this final text,” said Daniel Leufer, a senior policy analyst at the digital rights group Access Now. \\n___\\nTech reporter Matt O’Brien in Providence, Rhode Island, contributed to this report. \\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_1_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_1_preprocessed_text = preprocess_text(eu_1_article_text)\n",
    "eu_2_preprocessed_text = preprocess_text(eu_2_article_text)\n",
    "china_preprocessed_text = preprocess_text(china_article_text)\n",
    "uk_preprocessed_text = preprocess_text(uk_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friday parliament council negotiator reached provisional agreement artificial intelligence act regulation aim ensure fundamental right democracy rule law environmental sustainability protected high risk ai boosting innovation making europe leader field rule establish obligation ai based potential risk level impactbanned application recognising potential threat citizen right democracy posed certain application ai colegislators agreed prohibit l aw enforcement exemption negotiator agreed series safeguard narrow exception use biometric identification system rbi publicly accessible space law enforcement purpose subject prior judicial authorisation strictly defined list crime postremote rbi would used strictly targeted search person convicted suspected committed serious crime realtime rbi would comply strict condition use would limited time location purpose obligation highrisk systemsfor ai system classified highrisk due significant potential harm health safety fundamental right environment democracy rule law clear obligation agreed meps successfully managed include mandatory fundamental right impact assessment among requirement applicable also insurance banking sector ai system used influence outcome election voter behaviour also classified highrisk citizen right launch complaint ai system receive explanation decision based highrisk ai system impact rightsguardrails general artificial intelligence systemsto account wide range task ai system accomplish quick expansion capability agreed generalpurpose ai gpai system gpai model based adhere transparency requirement initially proposed parliament include drawing technical documentation complying eu copyright law disseminating detailed summary content used trainingfor highimpact gpai model systemic risk parliament negotiator managed secure stringent obligation model meet certain criterion conduct model evaluation ass mitigate systemic risk conduct adversarial testing report commission serious incident ensure cybersecurity report energy efficiency meps also insisted harmonised eu standard published gpais systemic risk may rely code practice comply regulationmeasures support innovation smesmeps wanted ensure business especially smes develop ai solution without undue pressure industry giant controlling value chain end agreement promotes socalled regulatory sandbox realworldtesting established national authority develop train innovative ai placement marketsanctions entry force noncompliance rule lead fine ranging million euro global turnover million turnover depending infringement size companyquotesfollowing deal corapporteur brando benifei italy said long intense effort worth thanks european parliament resilience world first horizontal legislation artificial intelligence keep european promise ensuring right freedom centre development groundbreaking technology correct implementation key parliament continue keep close eye ensure support new business idea sandbox effective rule powerful model corapporteur dragos tudorache renew romania said eu first world set place robust regulation ai guiding development evolution humancentric direction ai act set rule large powerful ai model ensuring present systemic risk union offer strong safeguard citizen democracy abuse technology public authority protects smes strengthens capacity innovate lead field ai protects vulnerable sector economy european union made impressive contribution world ai act another one significantly impact digital future press conference lead meps brando benifei italy dragos tudorache renew romania secretary state digitalisation artificial intelligence carme artigas commissioner thierry breton held joint press conference negotiation statement mr benifei available mr tudorache s extract available herenext stepsthe agreed text formally adopted parliament council become eu law parliament internal market civil liberty committee vote agreement forthcoming meeting'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_2_preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "573dfe784a97caf9dff8293e7ed0f9bd3e6f3d5163ce14a787b0340057cdb20e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
